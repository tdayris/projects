import os.path
import pandas

from pathlib import Path
from typing import Any, Dict, List

swv = "0.50.4"
git = "https://raw.githubusercontent.com/tdayris-perso/snakemake-wrappers"
base_dir = Path("/mnt/beegfs/scratch/bioinfo_core/B19095_INMA_01")

design = pandas.read_csv(
    base_dir / "design.tsv",
    sep="\t",
    header=0,
    index_col=1,
    dtype=str
)

design_dict = design.to_dict()


def sample_pair_w(wildcards: Any) -> Dict[str, str]:
    """
    Given a sample name, this function returns a pair of fastq files
    """
    return {
        "fq1": design_dict["Upstream_file"][wildcards.sample],
        "fq2": design_dict["Downstream_file"][wildcards.sample]
    }


def salmon_sample_pair_w(wildcards: Any) -> Dict[str, str]:
    """
    Same as above, rename keys
    """
    return {
        "r1": design_dict["Upstream_file"][wildcards.sample],
        "r2": design_dict["Downstream_file"][wildcards.sample]
    }


samplsdict = {
    os.path.basename(f): f
    for f in chain(
        design["Upstream_file"],
        design["Downstream_file"]
    )
}

localrules: download_gtf, download_fasta, download_fasta_cdna


rule all:
    input:
        # mixcr_tsv = expand(
        #     "mixcr/report/{sample}.tsv",
        #     sample=design.index.tolist()
        # ),
        # mixcr_bin = expand(
        #     "mixcr/assemble/{sample}.vdjca",
        #     sample=design.index.tolist()
        # ),
        multiqc = "qc/multiqc.html",
        tr2gene = "resources/tr_to_gene.tsv",
        # annotation = "pcaExplorer/annot.RDS",
        # limmago = "pcaExplorer/limmago.RDS",
        # pairwise_scatterplot = "figures/pairwise_scatterplot.png",
        count_table = "salmon/aggregated/TPM.counts.tsv",
        # boxplot = "figures/box_counts.png"
        pca = expand(
            "figures/PCA/PCA_{factor}_PC1_PC2.png",
            factor = ["Patient", "S", "Year", "Treatment"]
        ),
        pca_named = expand(
            "figures/PCA/PCA_{factor}_{names}_PC1_PC2.png",
            factor = ["Patient", "S", "Year", "Treatment"],
            names = design.index.tolist()
        ),
        deseq2 = expand(
            "deseq2/TSV/DESeq2_{factor}.tsv",
            factor = ["Patient"]
        )
    message:
        "Finishing pipeline"


rule mixcr_align:
    input:
        unpack(sample_pair_w)
    output:
        vdjca = temp("mixcr/align/{sample}.vdjca"),
        report = "mixcr/align_report/{sample}.report"
    message:
        "Aligning {wildcards.sample} on vcjca"
    message:
        "Align {wildcards.sample} against V, D, J, and C genes"
    threads:
        10
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(8192 * attempt, 20480)
        ),
        time_min = (
            lambda wildcards, attempt: min(90 * attempt, 380)
        )
    conda:
        "../../mixcr.yaml"
    log:
        "logs/mixcr/align/{sample}.logs"
    params:
        extra = "-p rna-seq -s hsa -OallowPartialAlignments=true"
    shell:
        "mixcr align"                # Tool and its subprocess
        " -t {threads}"              # Maximum number of threads
        " -r {output.report}"        # Path to report
        " {params.extra}"                   # Optional parameters
        " {input.fq1} {input.fq2} "  # Path to input file
        " {output.vdjca}"            # Path to vdjca file
        " > {log} 2>&1"              # Logging behavior


rule mixcr_assembly_1:
    input:
        "mixcr/align/{sample}.vdjca"
    output:
        temp("mixcr/assembly_1/{sample}.vdjca")
    message:
        "First pass of the assembly of {wildcards.sample}"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(4096 * attempt, 18432)
        ),
        time_min = (
            lambda wildcards, attempt: min(75 * attempt, 380)
        )
    conda:
        "../../mixcr.yaml"
    log:
        "logs/mixcr/assembly_1/{sample}.logs"
    params:
        extra = ""
    shell:
        "mixcr assemblePartial"  # Tool and its sub-command
        " {params.extra}"               # Optional parameters
        " {input}"               # Path to input file
        " {output}"              # Path to output file
        " > {log} 2>&1"          # Logging behavior


rule mixcr_assembly_2:
    input:
        "mixcr/assembly_1/{sample}.vdjca"
    output:
        temp("mixcr/assembly_2/{sample}.vdjca")
    message:
        "Second pass of the assembly of {wildcards.sample}"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(4096 * attempt, 18432)
        ),
        time_min = (
            lambda wildcards, attempt: min(75 * attempt, 380)
        )
    conda:
        "../../mixcr.yaml"
    log:
        "logs/mixcr/assembly_1/{sample}.logs"
    params:
        extra = ""
    shell:
        "mixcr assemblePartial"  # Tool and its sub-command
        " {params.extra}"               # Optional parameters
        " {input}"               # Path to input file
        " {output}"              # Path to output file
        " > {log} 2>&1"          # Logging behavior


rule mixcr_extend:
    input:
        "mixcr/assembly_2/{sample}.vdjca"
    output:
        temp("mixcr/extend/{sample}.vdjca")
    message:
        "Extending incomplete TCD CDR3s in {wildcards.sample}"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(4096 * attempt, 8192)
        ),
        time_min = (
            lambda wildcards, attempt: min(45 * attempt, 380)
        )
    conda:
        "../../mixcr.yaml"
    log:
        "logs/mixcr/extend/{sample}.logs"
    params:
        extra = ""
    shell:
        "mixcr extendAlignments"   # Tool and its subcommand
        " {params.extra}"       # Optional parameters
        " {input}"       # Path to input file
        " {output}"      # Path to output file
        " > {log} 2>&1"  # Logging behavior


rule mixcr_assemble:
    input:
        "mixcr/extend/{sample}.vdjca"
    output:
        vdjca = "mixcr/assemble/{sample}.vdjca",
        report = "mixcr/assemble_report/{sample}.report"
    message:
        "Assembling clonotypes for {wildcards.sample}"
    threads:
        10
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(4096 * attempt, 8192)
        ),
        time_min = (
            lambda wildcards, attempt: min(45 * attempt, 380)
        )
    conda:
        "../../mixcr.yaml"
    log:
        "logs/mixcr/assemble/{sample}.logs"
    params:
        extra = ""
    shell:
        "mixcr assemble"         # Tool and its sub-command
        " {params.extra}"               # Optional parameters
        " -t {threads}"          # Maximum number of threads
        " -r {output.report}"    # Path to report
        " {input}"               # Path to input file
        " {output.vdjca}"        # Path to output vdjca
        " > {log} 2>&1"          # Logging behavior


rule mixcr_export:
    input:
        "mixcr/assemble/{sample}.vdjca"
    output:
        "mixcr/report/{sample}.tsv"
    message:
        "Export clonotypes for {wildcards.sample}"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(1024 * attempt, 3072)
        ),
        time_min = (
            lambda wildcards, attempt: min(15 * attempt, 120)
        )
    conda:
        "../../mixcr.yaml"
    log:
        "logs/mixcr/export/{sample}.logs"
    params:
        extra = ""
    shell:
        "mixcr exportClones"  # Tool and its sub-command
        " {params.extra}"            # Optional arguments
        " {input}"            # Path to input file
        " {output}"           # Path to output file
        " > {log} 2>&1"       # Logging behavior


rule download_gtf:
    output:
        temp("resources/Homo_sapiens.gtf")
    message:
        "Downloading GTF from ensembl"
    params:
        species = "homo_sapiens",
        release = "98",
        build = "GRCh38",
        fmt = "gtf"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(128 * attempt, 512)
        ),
        time_min = (
            lambda wildcards, attempt: min(25 * attempt, 120)
        )
    log:
        "logs/ensembl_annotation/get_gtf.log"
    wrapper:
        f"{swv}/bio/reference/ensembl-annotation"


rule download_fasta:
    output:
        temp("resources/Homo_sapiens.fasta")
    message:
        "Downloading Fasta from ensembl"
    params:
        species = "homo_sapiens",
        release = "98",
        datatype = "dna",
        build = "GRCh38"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(128 * attempt, 512)
        ),
        time_min = (
            lambda wildcards, attempt: min(25 * attempt, 120)
        )
    log:
        "logs/ensembl_annotation/get_genome.log"
    wrapper:
        f"{swv}/bio/reference/ensembl-sequence"


rule star_index:
    input:
        fasta = ancient("resources/Homo_sapiens.fasta"),
        gtf = ancient("resources/Homo_sapiens.gtf")
    output:
        directory("star/index/Homo_sapiens")
    message:
        "Indexing GRCh38 with STAR"
    threads:
        10
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(35840 + 10240 * attempt, 51200)
        ),
        time_min = (
            lambda wildcards, attempt: min(35 * attempt, 120)
        )
    params:
        gtf = "resources/Homo_sapiens.gtf",
        sjdbOverhang = "100",
        extra = ""
    log:
        "logs/star/index.log"
    wrapper:
        f"{swv}/bio/star/index"


rule star_mapping:
    input:
        unpack(sample_pair_w),
        index = ancient("star/index/Homo_sapiens")
    output:
        temp("star/bam/{sample}/Aligned.sortedByCoord.out.bam")
    message:
        "Mapping {wildcards.sample} with STAR"
    threads:
        10
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(35840 + 10240 * attempt, 51200)
        ),
        time_min = (
            lambda wildcards, attempt: min(50 * attempt, 120)
        )
    params:
        index = "star/index/Homo_sapiens",
        extra = ("--outSAMtype BAM SortedByCoordinate "
                 "--outSAMattributes All "
                 "--outFilterType BySJout "
                 "--outFilterMismatchNmax 999 "
                 "--alignSJDBoverhangMin 1 "
                 "--outFilterMismatchNoverReadLmax 0.04 "
                 "--alignMatesGapMax 1000000 "
                 "--alignIntronMax 1000000 "
                 "--alignIntronMin 20 "
                 "--alignSJoverhangMin 8 "
                 "--outFilterMultimapNmax 20 "
                 "--twopassMode Basic")
    log:
        "logs/star/bam/{sample}.log"
    wrapper:
        f"{swv}/bio/star/align"


rule star_rename:
    input:
        "star/bam/{sample}/Aligned.sortedByCoord.out.bam"
    output:
        "star/bam/{sample}.bam"
    message:
        "Renaming {wildcards.sample} for further analyses"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(128 * attempt, 512)
        ),
        time_min = (
            lambda wildcards, attempt: min(5 * attempt, 15)
        )
    params:
        ""
    log:
        "logs/rename/{sample}.log"
    shell:
        "cp -v {input} {output} > {log} 2>&1"


rule samtools_index:
    input:
        "star/bam/{sample}.bam"
    output:
        "star/bam/{sample}.bam.bai"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(512 * attempt, 1024)
        ),
        time_min = (
            lambda wildcards, attempt: min(15 * attempt, 45)
        )
    params:
        ""
    wrapper:
        f"{swv}/bio/samtools/index"


rule samtools_flagstat:
    input:
        "star/bam/{sample}.bam"
    output:
        temp("samtools/flagstat/{sample}.flagstat")
    message:
        "Gathering statistics on {wildcards.sample}'s mapping"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(512 * attempt, 1024)
        ),
        time_min = (
            lambda wildcards, attempt: min(15 * attempt, 45)
        )
    params:
        ""
    wrapper:
        f"{swv}/bio/samtools/flagstat"


rule download_fasta_cdna:
    output:
        temp("resources/Homo_sapiens_cdna_patch.fasta")
    message:
        "Downloading Fasta from ensembl"
    params:
        species = "homo_sapiens",
        release = "98",
        datatype = "cdna",
        build = "GRCh38"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(128 * attempt, 512)
        ),
        time_min = (
            lambda wildcards, attempt: min(25 * attempt, 120)
        )
    log:
        "logs/ensembl_annotation/get_genome.log"
    wrapper:
        f"{swv}/bio/reference/ensembl-sequence"


rule correct_cdna_patch:
    input:
        ancient("resources/Homo_sapiens_cdna_patch.fasta")
    output:
        "resources/Homo_sapiens_cdna.fasta"
    message:
        "Removing patch ids from ensembl transcripts names"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    log:
        "logs/correct_cdna_patch.log"
    shell:
        "sed 's/\.[0-9]* / /g' {input} > {output} 2> {log}"


rule salmon_index:
    input:
        ancient("resources/Homo_sapiens_cdna.fasta")
    output:
        directory("salmon/index/Homo_sapiens")
    message:
        "Indexing hsa with Salmon"
    threads:
        10
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(8192 + 1024 * attempt, 15360)
        ),
        time_min = (
            lambda wildcards, attempt: min(25 * attempt, 120)
        )
    params:
        extra = "--keepDuplicates --perfectHash"
    log:
        "logs/salmon/index.log"
    wrapper:
        f"{swv}/bio/salmon/index"


rule salmon_quant:
    input:
        unpack(salmon_sample_pair_w),
        index = "salmon/index/Homo_sapiens"
    output:
        quant = "salmon/quant/{sample}/quant.sf"
    message:
        "Quantifying {wildcards.sample} with Salmon"
    threads:
        10
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(8192 + 1024 * attempt, 15360)
        ),
        time_min = (
            lambda wildcards, attempt: min(115 * attempt, 480)
        )
    params:
        libtype = "A",
        extra = "--numBootstraps 100 --validateMappings --gcBias --seqBias"
    log:
        "logs/salmon/quant/{sample}.log"
    wrapper:
        f"{swv}/bio/salmon/quant"


rule fastqc:
    input:
        lambda wildcards: samplsdict[wildcards.sample]
    output:
        html = "qc/fastqc/{sample}.html",
        zip = "qc/fastqc/{sample}_fastqc.zip"
    message:
        "Controlling quality of {wildcards.sample}"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(1024 + 1024 * attempt, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(30 * attempt, 120)
        )
    params:
        ""
    log:
        "logs/fastqc/{sample}.log"
    wrapper:
        f"{swv}/bio/fastqc"


rule multiqc:
    input:
        expand(
            "salmon/quant/{sample}/quant.sf",
            sample=design.index.tolist()
        ),
        expand(
            "samtools/flagstat/{sample}.flagstat",
            sample=design.index.tolist()
        ),
        expand(
            "qc/fastqc/{sample}{ext}",
            sample=samplsdict.keys(),
            ext=[".html", "_fastqc.zip"]
        )
    output:
        report(
            "qc/multiqc.html",
            caption="../../reports/MultiQC.report.rst",
            category="Quality Controls"
        )
    message:
        "Gathering quality controls"
    params:
        ""
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(1024 + 1024 * attempt, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(30 * attempt, 120)
        )
    log:
        "logs/multiqc.log"
    wrapper:
        f"{swv}/bio/multiqc"

rule tx2gene:
    input:
        gtf = "resources/Homo_sapiens.gtf"
    output:
        tsv = temp("deseq2/Homo_sapiens.tsv")
    message:
        "Building T2G table"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: attempt * 2048
        ),
        time_min = (
            lambda wildcards, attempt: attempt * 119
        )
    log:
        "logs/tx2gene.log"
    wrapper:
        f"{git}/tx_to_tgene/bio/tx_to_gene/gtf"


rule tr2gene:
    input:
        "deseq2/Homo_sapiens.tsv"
    output:
        temp("deseq2/Homo_sapiens.tximport.tsv")
    message:
        "Reducing the tx2gene table for tximport"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 512, 1024)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 10, 20)
        )
    log:
        "logs/tx2gene.log"
    shell:
        "cut -f1,3 {input} > {output} 2> {log}"


rule tximport:
    input:
        quant = expand(
            "salmon/quant/{sample}/quant.sf",
            sample=design.index.tolist()
        ),
        tx_to_gene = "deseq2/Homo_sapiens.tximport.tsv"
    output:
        txi = temp("deseq2/txi.RDS")
    message:
        "Gathering transcript counts for DESeq2"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(20480 * attempt, 61040)
        ),
        time_min = (
            lambda wildcards, attempt: 240 * attempt
        )
    log:
        "logs/tximport.log"
    wrapper:
        f"{swv}/bio/tximport"


rule deseq2_dds:
    input:
        tximport = ancient("deseq2/txi.RDS"),
        coldata = "design.tsv"
    output:
        dds = temp("deseq2/RDS/DESeq2_dds_{factor}.RDS")
    message:
        "Building Deseq2 dataset"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 8192, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 40, 200)
        )
    params:
        design = (
            lambda wildcards: {
                "Patient": '~Patient'
            }[wildcards.factor]
        )
    log:
        "logs/deseq2/dds/{factor}.log"
    wrapper:
        f"{git}/deseq2_dataset/bio/deseq2/DESeqDataSetFromTximport"


rule deseq2_esf:
    input:
        dds = "deseq2/RDS/DESeq2_dds_{factor}.RDS"
    output:
        dds = temp("deseq2/RDS/DEseq2_esf_{factor}.RDS")
    message:
        "Estimating size factors for {wildcards.factor}"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 8192, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 40, 200)
        )
    params:
        locfunc = "median"
    log:
        "logs/deseq2/esf.log"
    wrapper:
        f"{git}/deseq2-estimateSizeFactors/bio/deseq2/estimateSizeFactors"


rule deseq2_disp:
    input:
        dds = "deseq2/RDS/DEseq2_esf_{factor}.RDS"
    output:
        disp = temp("deseq2/RDS/DESeq2_DispEst_{factor}.RDS")
    message:
        "Estimating sample dispersion for {factor}"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 8192, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 45, 200)
        )
    log:
        "logs/deseq2/disp/{factor}.log"
    params:
        fittype = "parametric"
    wrapper:
        f"{git}/deseq2-disp.R/bio/deseq2/estimateDispersions"


rule deseq2_vst:
    input:
        dds = "deseq2/RDS/DESeq2_DispEst_{factor}.RDS"
    output:
        rds = temp("deseq2/RDS/DESeq2_vst_{factor}.RDS"),
        tsv = "deseq2/TSV/DEseq2_VST_{factor}.tsv"
    message:
        "Computing variance stabilizing transform for {wildcards.factor}"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: attempt * 8192
        ),
        time_min = (
            lambda wildcards, attempt: attempt * 40
        )
    log:
        "logs/deseq2/vst/{factor}.log"
    wrapper:
        f"{git}/deseq2-vst/bio/deseq2/vst"


# rule pcaexplorer:
#     input:
#         dst = "deseq2/vst.RDS",
#         dds = "deseq2/dds.RDS",
#         tr2gene = "resources/tr_to_gene.tsv"
#     output:
#         annotation = "pcaExplorer/annot.RDS",
#         limmago = "pcaExplorer/limmago.RDS"
#     message:
#         "Preparing pcaExplorer"
#     threads:
#         1
#     resources:
#         mem_mb = (
#             lambda wildcards, attempt: min(attempt * 8192, 10240)
#         ),
#         time_min = (
#             lambda wildcards, attempt: min(attempt * 20, 200)
#         )
#     conda:
#         "Renv.yaml"
#     log:
#         "logs/pcaexplorer/prepare.log"
#     params:
#         organism = "Hs"
#     script:
#         "pcaex.R"

rule pandas_merge:
    input:
        quant = expand(
            "salmon/quant/{sample}/quant.sf",
            sample=design.index.tolist()
        ),
        tx2gene = "deseq2/Homo_sapiens.tsv"
    output:
        tsv = report(
            "salmon/aggregated/TPM.counts.tsv",
            caption="../../reports/aggregated.TPM.counts.rst",
            category="Counts"
        )
    message:
        "Aggregating salmon counts"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    log:
        "logs/pandas_merge.log"
    wrapper:
        f"{git}/pandas-merge/bio/pandas/salmon"


rule box_count:
    input:
        counts = "salmon/aggregated/TPM.counts.tsv"
    output:
        png = report(
            "figures/box_counts.png",
            caption="../../reports/box.counts.rst",
            category="Figures"
        )
    message:
        "Plotting comparative boxplots of each sample's counts"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    log:
        "logs/box_count.log"
    wrapper:
        f"{git}/pandas-merge/bio/seaborn/box-counts"


rule pairwise_scatterplot:
    input:
        counts = "salmon/aggregated/TPM.counts.tsv"
    output:
        png = report(
            "figures/pairwise_scatterplot.png",
            caption="../../reports/pairwise_scatterplot.rst",
            category="Figures"
        )
    message:
        "Drawing pairwise scatterplot"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 8192, 16384)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    log:
        "logs/pairwise_scatterplot.log"
    wrapper:
        f"{git}/pandas-merge/bio/seaborn/pairwise-scatterplot"


rule pca_plots:
    input:
        counts = "salmon/aggregated/TPM.counts.tsv"
    output:
        png = report(
            "figures/PCA/PCA_{factor}_PC1_PC2.png",
            caption="../../reports/pca.rst",
            category="Figures"
        )
    message:
        "Plotting PCA for factor {wildcards.factor}"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: attempt * 2048
        ),
        time_min = (
            lambda wildcards, attempt: attempt * 40
        )
    params:
        axes = [1, 2],
        conditions = lambda wildcards: {
            k: v for k, v in zip(
                design.index.tolist(),
                design[wildcards.factor].tolist()
            )
        },
        prefix = (
            lambda wildcards: f"figures/PCA/PCA_{wildcards.factor}"
        )
    log:
        "logs/pca_plots/{factor}.log"
    wrapper:
        f"{git}/pandas-merge/bio/seaborn/pca"


rule pca_plots_namd:
    input:
        counts = "salmon/aggregated/TPM.counts.tsv"
    output:
        png = report(
            "figures/PCA/PCA_{factor}_{names}_PC1_PC2.png",
            caption="../../reports/pca.rst",
            category="Figures"
        )
    message:
        "Plotting PCA for factor {wildcards.factor}"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: attempt * 2048
        ),
        time_min = (
            lambda wildcards, attempt: attempt * 40
        )
    params:
        axes = [1, 2],
        conditions = lambda wildcards: {
            k: v for k, v in zip(
                design.index.tolist(),
                design[wildcards.factor].tolist()
            )
        },
        samples_names = True,
        prefix = (
            lambda wildcards: f"figures/PCA/PCA_{wildcards.factor}_{wildcards.names}"
        )
    wildcard_constraints:
        factor = "|".join(["Patient", "S", "Year", "Treatment"]),
        names = "|".join(design.index.tolist())
    log:
        "logs/pca_plots/{factor}.log"
    wrapper:
        f"{git}/pandas-merge/bio/seaborn/pca"


rule deseq2_waldtest:
    input:
        dds = "deseq2/RDS/DESeq2_DispEst_{factor}.RDS"
    output:
        rds = "deseq2/RDS/DESeq2_WaldTest_{factor}.RDS",
        tsv = report(
            "deseq2/TSV/DESeq2_{factor}.tsv",
            caption="../../reports/deseq2.complete.table.rst",
            category="Differential Expression"
        )
    message:
        "Performing DESeq2 wald test on {wildcards.factor}"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: attempt * 5125
        ),
        time_min = (
            lambda wildcards, attempt: attempt * 30
        )
    log:
        "logs/deseq2_waldtest/{factor}.log"
    wrapper:
        f"{swv}/deseq2-waldtest/bio/deseq2/nbinomWaldTest"
