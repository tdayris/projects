import sys
import pandas
import os.path

from snakemake.utils import min_version, makedirs
from pathlib import Path
from typing import Any, Dict

if sys.version_info < (3, 8):
    raise SystemError("Please use Python 3.8 or later")

min_version('5.16.0')
git = "https://raw.githubusercontent.com/tdayris/snakemake-wrappers/Unofficial"
container: "docker://continuumio/miniconda3:5.0.1"


compressed_vcf = Path(
    "/mnt/beegfs/scratch/bioinfo_core/B19111_ETRO_01/annovar/snpsift/GeneSets/"
)

vcf_paths = {
    str(f.name)[:-7]: f
    for f in compressed_vcf.iterdir()
    if str(f).endswith(".vcf.gz")
}

rule all:
    input:
        expand("snpsfit/table/{sample}.tsv", sample=vcf_paths.keys())
    message:
        "Finishing pipeline"


rule tabix_index:
    input:
        "{file}"
    output:
        "{file}.tbi"
    message:
        "Indexing {wildcards.file}"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    params:
        "-p vcf"
    log:
        "logs/tabix/{file}.log"
    wrapper:
        f"{git}/bio/tabix"


rule snpsift_filter:
    input:
        vcf = lambda w: str(vcf_paths[w.sample]),
        idx = lambda w: f"{vcf_paths[w.sample]}.tbi"
    output:
        vcf = temp("snpsift/filtered/{sample}.vcf.gz")
    message:
        "Filtering {wildcards.sample}"
    threads:
        4
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    params:
        snpsift_filters = "((! exists dbNSFP_ExAC_NFE_AF) | (dbNSFP_ExAC_NFE_AF <= 0.01))",
        bcftools_filter = "FORMAT/AD>5",
        view_filters = "-M 1"
    conda:
        "../../envs/biotools.yaml"
    log:
        view = "logs/bcftools/view/{sample}.log",
        bcftools_filter = "logs/bcftools/filter/{sample}.log",
        snpsift_filter = "logs/snpsift/filter/{sample}.log",
        bgzip = "logs/bgzip/filter/{sample}.log"
    shell:
        " bcftools filter "
        " --include '{params.bcftools_filter}' "
        " --output-type v "
        " {input.vcf} "
        " 2> {log.bcftools_filter} "
        " | "
        "  SnpSift filter "
        "'{params.snpsift_filters}' "
        " 2> {log.snpsift_filter} "
        " | "
        " bgzip -c > {output.vcf} "
        "2> {log.bgzip}"


rule snpsift_vartype:
    input:
        vcf = "snpsift/filtered/{sample}.vcf.gz"
    output:
        vcf = temp("snpsift/varType/{sample}.vcf")
    message:
        "Computing variant type for {wildcards.sample}"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    group:
        "split_variants"
    log:
        "logs/snpsift/vartype/{sample}.log"
    wrapper:
        f"{git}/bio/snpsift/varType"


FIELDS = (
    "CHROM "                             # 0
    "POS "
    "REF "
    "ALT "
    "FILTER "
    "VAF "                              # 5
    "NAD "
    "NRD "
    "NDP "
    "ANN[*].EFFECT "
    "ANN[*].GENE "                      # 10
    "ANN[*].GENEID "
    "ANN[*].IMPACT "
    "ANN[*].HGVS_P "
    "ANN[*].HGVS_C "
    "ANN[*].CDNA_POS "                  # 15
    "ANN[*].BIOTYPE "
    "dbNSFP_Interpro_domain "
    "dbNSFP_1000Gp3_EUR_AC "
    "dbNSFP_Uniprot_acc "
    "dbNSFP_SIFT_pred "                 # 20
    "dbNSFP_MetaSVM_pred "
    "dbNSFP_MutationTaster_pred "
    "dbNSFP_MutationAssessor_pred "
    "dbNSFP_PROVEAN_pred "
    "dbNSFP_LRT_pred "                  # 25
    "dbNSFP_Polyphen2_HDIV_pred "
    "dbNSFP_FATHMM_pred "
    "GWASCAT_PUBMED_ID "
    "MSigDb "
    "dbNSFP_ExAC_NFE_AF "               # 30
    "dbNSFP_ExAC_SAS_AF "
    "dbNSFP_ExAC_Adj_AF "
    "dbNSFP_ExAC_AFR_AF "
    "dbNSFP_ExAC_AF "
    "dbNSFP_ExAC_FIN_AF "               # 35
    "dbNSFP_1000Gp3_EUR_AF "
    "dbNSFP_ExAC_AMR_AF "
    "dbNSFP_ExAC_EAS_AF "
    "dbNSFP_ESP6500_EA_AF "
    "dbNSFP_1000Gp3_AMR_AF "            # 40
    "dbNSFP_1000Gp3_AF "
    "dbNSFP_1000Gp3_EAS_AF "
    "dbNSFP_1000Gp3_EUR_AF "
    "dbNSFP_1000Gp3_AFR_AF "
    "dbNSFP_1000Gp3_SAS_AF"             # 45
)

rule compress_and_index:
    input:
        "snpsift/varType/{sample}.vcf"
    output:
        vcf = "snpsift/varType/{sample}.vcf.gz",
        tbi = "snpsift/varType/{sample}.vcf.gz.tbi"
    message:
        "Compressing and indexing {wildcars.sample}"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    group:
        "format"
    log:
        "logs/compress_and_index/{sample}.log"
    conda:
        "../../envs/biotools.yaml"
    shell:
        "bgzip -c {input} > {output.vcf} && tabix -p vcf {input}"

rule calculate_vaf:
    input:
        "snpsift/varType/{sample}.vcf.gz"
    output:
        temp("snpsift/vafed/{sample}.vcf.gz")
    message:
        "Filtering on VAF"
    threads:
        2
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    group:
        "format"
    # conda:
    #     "../../envs/py37.yaml"
    log:
        "logs/calculate_vaf/{sample}.log"
    run:
        import gzip
        never = True

        with gzip.open(input[0], "rb") as vcf, gzip.open(output[0], "w") as out:
            for line in vcf:
                if line.startswith(b"#"):
                    out.write(line)
                    if never is True:
                        out.write(b"##INFO=<ID=VAF,Number=A,Type=Float,Description=\"Variant Allele frequency\">\n")
                        out.write(b"##INFO=<ID=NAD,Number=A,Type=Float,Description=\"Variant allele depth\">\n")
                        out.write(b"##INFO=<ID=NDP,Number=A,Type=Float,Description=\"Read depth\">\n")
                        out.write(b"##INFO=<ID=NRD,Number=A,Type=Float,Description=\"Reference allele depth\">\n")
                        never = False
                    continue

                chomp = line[:-1].split(b"\t")
                try:
                    sample = {
                        f: s
                        for f, s in zip(
                            chomp[8].split(b":"),
                            chomp[9].split(b":")
                        )
                    }
                    vaf = int(sample[b"AD"].split(b",")[1]) / int(sample[b"DP"])
                    if vaf > 0.1:
                        chomp[7] += b";VAF=" + str(vaf).encode()
                        chomp[7] += b";NAD=" + sample[b"AD"]
                        chomp[7] += b";NDP=" + sample[b"DP"]
                        chomp[7] += b";NRD=" + str(int(sample[b"DP"]) - int(sample[b"AD"].split(b",")[1])).encode()
                        out.write(b"\t".join(chomp) + b"\n")

                except KeyError:
                    pass
                except ZeroDivisionError:
                    pass



rule snpsift_table:
    input:
        vcf = "snpsift/vafed/{sample}.vcf.gz"
    output:
        tsv = "snpsfit/table/{sample}.tsv"
    message:
        "Building table from vcf file"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    conda:
        "../../envs/biotools.yaml"
    group:
        "format"
    params:
        fields = FIELDS
    log:
        "logs/snpsift_table/{sample}.log"
    shell:
        "SnpSift extractFields "
        " -e '.' "
        " -s ',' "
        " {input.vcf} "
        " {params.fields} "
        " > {output.tsv} "
        " 2> {log}"
