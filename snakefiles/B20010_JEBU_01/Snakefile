import sys
import pandas
import os.path

from snakemake.utils import min_version, makedirs
from pathlib import Path
from typing import Any, Dict

if sys.version_info < (3, 8):
    raise SystemError("Please use Python 3.8 or later")

min_version('5.16.0')
git = "https://raw.githubusercontent.com/tdayris/snakemake-wrappers/Unofficial"
containers: "docker://continuumio/miniconda3:5.0.1"

design_path = Path("design.tsv")
if not design_path.exists():
    raise FileNotFoundError(f"Could not find {str(design_path)}")

design = pandas.read_csv(
    design_path,
    sep="\t",
    header=0,
    index_col=None,
    dtype=str
)

design["Upstream_copy"] = [
    os.path.join("raw_data", os.path.basename(p))
    for p in design.Upstream_file
]

design["Downstream_copy"] = [
    os.path.join("raw_data", os.path.basename(p))
    for p in design.Downstream_file
]

design_dict = design.to_dict()

fqc_dict = {
    Path(p).stem: p
    for p in chain(design.Upstream_file, design.Downstream_file)
}


rule all:
    input:
        fqc_html = expand("fastqc/{sample}_fastqc.html", sample=fqc_dict.keys())
    message:
        "Finishing pipeline "


rule fastqc:
    input:
        lambda wildcards: str(fqc_dict[wildcards.sample])
    output:
        html = "fastqc/{sample}_fastqc.html",
        zip = "fastqc/{sample}_fastqc.zip"
    message:
        "Controling quality of {wildcards.sample}"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 8096)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 45, 120)
        )
    params:
        ""
    log:
        "logs/fastqc/{sample}.log"
    wrapper:
        f"{git}/bio/fastqc"


rule multiqc:
    input:
        fqc = expand(
            "fastqc/{sample}_fastqc.{ext}",
            sample=fqc_dict.keys(),
            ext=["zip", "html"]
        ),
        salmon = expand(
            "salmon/quant/{sample}/quant.sf",
            sample=design.Sample_id
        )
    output:
        report(
            "multiqc/report.html",
            caption="../../reports/MultiQC.report.rst",
            category="Quality Controls"
        )
    message:
        "Gathering quality reports"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    log:
        "logs/multiqc.log"
    wrapper:
        f"{git}/bio/multiqc"


rule download_fasta_cdna:
    output:
        temp("resources/homo_sapiens_cdna_patch.fasta")
    message:
        "Downloading Fasta from ensembl"
    params:
        species = "homo_sapiens",
        release = "98",
        datatype = "cdna",
        build = "GRCh38"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(128 * attempt, 512)
        ),
        time_min = (
            lambda wildcards, attempt: min(60 * attempt, 120)
        )
    log:
        "logs/ensembl_annotation/homo_sapiens_cdna_patch.log"
    wrapper:
        f"{git}/bio/reference/ensembl-sequence"


rule correct_cdna_patch:
    input:
        "resources/homo_sapiens_cdna_patch.fasta"
    output:
        temp("resources/homo_sapiens_cdna.fasta")
    message:
        "Removing patch ids from ensembl transcripts names"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(256 + attempt * 128, 512)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    log:
        "logs/ensembl_annotation/homo_sapiens_cdna.log"
    shell:
        "sed 's/.[0-9]* / /g' {input} > {output} 2> {log}"


# TODO: Add download_gtf in localrules
# TODO: Add to all: ensemblgtf = "resources/homo_sapiens.gtf"

rule download_gtf:
    output:
        temp("resources/homo_sapiens.gtf")
    message:
        "Downloading GTF from ensembl"
    params:
        species = "homo_sapiens",
        release = "98",
        fmt = "gtf",
        build = "GRCh38"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(128 * attempt, 512)
        ),
        time_min = (
            lambda wildcards, attempt: min(60 * attempt, 120)
        )
    log:
        "logs/ensembl_annotation/homo_sapiens_gtf.log"
    wrapper:
        f"{git}/bio/reference/ensembl-annotation"


# TODO: Add to all:
# expand("salmon/quant/{sample}/quant.sf", sample=design.Sample_id)

rule salmon_index:
    input:
        "resources/homo_sapiens_cdna.fasta"
    output:
        directory("salmon/index/homo_sapiens")
    message:
        "Indexing homo_sapiens CDNA with Salmon"
    threads:
        20
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(8192 + 1024 * attempt, 15360)
        ),
        time_min = (
            lambda wildcards, attempt: min(25 * attempt, 120)
        )
    params:
        extra = "--keepDuplicates --perfectHash"
    log:
        "logs/salmon/index_homo_sapiens.log"
    wrapper:
        f"{git}/bio/salmon/index"


def salmon_sample_pair_w(wildcards: Any) -> Dict[str, str]:
    return {
        "r1": design_dict[Upstream_file][wildcards.sample],
        "r2": design_dict[Downstream_file][wildcards.sample]
    }


rule salmon_quant:
    input:
        unpack(salmon_sample_pair_w),
        index = "salmon/index/homo_sapiens",
        gtf = "resources/homo_sapiens.gtf"
    output:
        quant = "salmon/quant/{sample}/quant.sf"
    message:
        "Quantifying {wildcards.sample} with Salmon"
    threads:
        20
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(8192 + 1024 * attempt, 15360)
        ),
        time_min = (
            lambda wildcards, attempt: min(45 * attempt, 120)
        )
    params:
        libtype = "A",
        extra = "--numBootstraps 100 --validateMappings --gcBias --seqBias --geneMap resources/homo_sapiens.gtf"
    log:
        "logs/salmon/quant/homo_sapiens_{sample}.log"
    wrapper:
        f"{git}/bio/salmon/quant"


rule tx2gene:
    input:
        gtf = "resources/Homo_sapiens.gtf"
    output:
        tsv = temp("deseq2/Homo_sapiens.tsv")
    message:
        "Building T2G table"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 512, 1024)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 10, 20)
        )
    params:
        gencode = True
    log:
        "logs/tx2gene.log"
    wrapper:
        f"{git}/tx_to_tgene/bio/tx_to_gene/gtf"

rule pandas_merge:
    input:
        quant = expand(
            "salmon/quant/{sample}/quant.genes.sf",
            sample=design.index.tolist()
        ),
        tx2gene = "deseq2/Homo_sapiens.tsv"
    output:
        tsv = report(
            "salmon/aggregated/TPM.counts.tsv",
            caption="../report/aggregated.TPM.counts.rst",
            category="Counts"
        )
    message:
        "Aggregating salmon counts"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    log:
        "logs/pandas_merge.log"
    wrapper:
        f"{git}/pandas-merge/bio/pandas/salmon"


rule box_count:
    input:
        "salmon/aggregated/TPM.counts.tsv"
    output:
        png = report(
            "figures/box_counts.png",
            caption="../../reports/box.counts.rst",
            category="Figures"
        )
    message:
        "Plotting comparative boxplots of each sample's counts"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    log:
        "logs/box_count.log"
    wrapper:
        f"{git}/pandas-merge/bio/seaborn/box-counts"


rule pairwise_scatterplot:
    input:
        counts = "salmon/aggregated/TPM.counts.tsv"
    output:
        png = report(
            "figures/pairwise_scatterplot.png",
            caption="../../reports/pairwise_scatterplot.rst",
            category="Figures"
        )
    message:
        "Drawing pairwise scatterplot"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 8192, 16384)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    log:
        "logs/pairwise_scatterplot.log"
    wrapper:
        f"{git}/pandas-merge/bio/seaborn/pairwise-scatterplot"


rule copy_quantiseq_image:
    input:
        "/mnt/beegfs/userdata/t_dayris/devs/quantiseq2.img"
    output:
        "quantiseq2.img"
    message:
        "Copying the quanTIseq image"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    conda:
        "../../envs/bash.yaml"
    params:
        "--verbose"
    log:
        "logs/quanTIseq/copy_quantiseq_image.log"
    shell:
        "cp {params} {input} {output} > {log} 2>&1"


rule filter_counts:
    input:
        "salmon/aggregated/TPM.counts.tsv"
    output:
        "quanTIseq/TPM.tsv"
    message:
        "Filtering counts for quanTIseq"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: attempt * 4096
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    conda:
        "../../envs/bash.yaml"
    log:
        "logs/quanTIseq/filter_counts.log"
    shell:
        "awk ' "
        " BEGIN {{FS=\"\\t\"}} "
        " {{ "
        " if (NR == 1) "
        " {{ "
        " print 'GENE' 'MR254-T1' 'MR263-T1' 'MR263-T2' 'MR275-T1' "
        "'MR275_RE-T2' 'MR307-T1' 'MR307-T2' 'MR307-T2' 'MR314-T1' "
        "'MR314-T2' 'MR316-T1' 'MR316-T2' 'MR334-T1' 'MR334-T2' "
        "'MR338-T1' 'MR338-T2' 'MR360-T1' 'MR360-T2'"
        " }} "
        " else "
        " {{ "
        " print $18 $1 $2 $3 $4 $5 $6 $7 $8 "
        " $9 $10 $11 $12 $13 $14 $15 $16 $17 "
        " }} "
        " }}"
        " ' "
        " {input} "
        " > {output} "
        " 2> {log} "


rule run_quanTIseq:
    input:
        counts = "quanTIseq/TPM.tsv",
        img = "quantiseq2.img"
    output:
        "quanTIseq/quanTIseq_cell_fractions.txt"
    message:
        "Estimating immune cell fraction"
    threads:
        10
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 512, 4096)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    conda:
        "../../envs/immunedeconv.yaml"
    log:
        "logs/quanTIseq/run.log"
    params:
        outdir = "quanTIseq",
        path = "/mnt/beegfs/userdata/t_dayris/projects",
        extra = (
            "--pipelinestart=decon "
            "--tumor=TRUE "
            "--mRNAscale=TRUE "
        )
    shell:
        "{params.path}/scripts/quanTIseq_pipeline.sh "
        " --inputfile={input.counts} "
        " --outputdir={params.outdir} "
        " --threads={threads} "
        " {params.extra} "
        " > {log} 2>&1 "


rule plot_quantiseq:
    input:
        fraction = "quanTIseq/quanTIseq_cell_fractions.txt"
    output:
        dotplots = "quanTIseq/cell_fraction_dotplot.png",
        histogram = "quanTIseq/cell_fraction_histogram.png"
    message:
        "Plotting immune cell fraction"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    conda:
        "../../envs/immunedeconv.yaml"
    log:
        "logs/quanTIseq/plot.log"
    script:
        "../../scripts/quanTIseq_plot.R"
