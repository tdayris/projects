import sys
import pandas
import os.path

from snakemake.utils import min_version, makedirs
from pathlib import Path
from typing import Any, Dict

if sys.version_info < (3, 8):
    raise SystemError("Please use Python 3.8 or later")

min_version('5.13.0')
wrapper_version = '0.50.4'
git = "https://raw.githubusercontent.com/tdayris-perso/snakemake-wrappers"
containers: "docker://continuumio/miniconda3:5.0.1"

design_path = Path("design.tsv")
if not design_path.exists():
    raise FileNotFoundError(f"Could not find {str(design_path)}")

design = pandas.read_csv(
    design_path,
    sep="\t",
    header=0,
    index_col=None,
    dtype=str
)

design["Upstream_copy"] = [
    os.path.join("raw_data", os.path.basename(p))
    for p in design.Upstream_file
]

design["Downstream_copy"] = [
    os.path.join("raw_data", os.path.basename(p))
    for p in design.Downstream_file
]

design_dict = design.to_dict()

fqc_dict = {
    Path(p).stem: p
    for p in chain(design.Upstream_file, design.Downstream_file)
}


rule all:
    input:
        fqc_html = expand("fastqc/{sample}_fastqc.html", sample=fqc_dict.keys())
    message:
        "Finishing pipeline "


rule fastqc:
    input:
        lambda wildcards: str(fqc_dict[wildcards.sample])
    output:
        html = "fastqc/{sample}_fastqc.html",
        zip = "fastqc/{sample}_fastqc.zip"
    message:
        "Controling quality of {wildcards.sample}"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 8096)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 45, 120)
        )
    params:
        ""
    log:
        "logs/fastqc/{sample}.log"
    wrapper:
        f"{wrapper_version}/bio/fastqc"


rule multiqc:
    input:
        fqc = expand(
            "fastqc/{sample}_fastqc.{ext}",
            sample=fqc_dict.keys(),
            ext=["zip", "html"]
        ),
        salmon = expand(
            "salmon/quant/{sample}/quant.sf",
            sample=design.Sample_id
        )
    output:
        report(
            "multiqc/report.html",
            caption="../../reports/MultiQC.report.rst",
            category="Quality Controls"
        )
    message:
        "Gathering quality reports"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    log:
        "logs/multiqc.log"
    wrapper:
        f"{wrapper_version}/bio/multiqc"


rule download_fasta_cdna:
    output:
        temp("resources/homo_sapiens_cdna_patch.fasta")
    message:
        "Downloading Fasta from ensembl"
    params:
        species = "homo_sapiens",
        release = "98",
        datatype = "cdna",
        build = "GRCh38"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(128 * attempt, 512)
        ),
        time_min = (
            lambda wildcards, attempt: min(60 * attempt, 120)
        )
    log:
        "logs/ensembl_annotation/homo_sapiens_cdna_patch.log"
    wrapper:
        f"{wrapper_version}/bio/reference/ensembl-sequence"


rule correct_cdna_patch:
    input:
        "resources/homo_sapiens_cdna_patch.fasta"
    output:
        temp("resources/homo_sapiens_cdna.fasta")
    message:
        "Removing patch ids from ensembl transcripts names"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(256 + attempt * 128, 512)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    log:
        "logs/ensembl_annotation/homo_sapiens_cdna.log"
    shell:
        "sed 's/.[0-9]* / /g' {input} > {output} 2> {log}"


# TODO: Add download_gtf in localrules
# TODO: Add to all: ensemblgtf = "resources/homo_sapiens.gtf"

rule download_gtf:
    output:
        temp("resources/homo_sapiens.gtf")
    message:
        "Downloading GTF from ensembl"
    params:
        species = "homo_sapiens",
        release = "98",
        fmt = "gtf",
        build = "GRCh38"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(128 * attempt, 512)
        ),
        time_min = (
            lambda wildcards, attempt: min(60 * attempt, 120)
        )
    log:
        "logs/ensembl_annotation/homo_sapiens_gtf.log"
    wrapper:
        f"{wrapper_version}/bio/reference/ensembl-annotation"


# TODO: Add to all:
# expand("salmon/quant/{sample}/quant.sf", sample=design.Sample_id)

rule salmon_index:
    input:
        "resources/homo_sapiens_cdna.fasta"
    output:
        directory("salmon/index/homo_sapiens")
    message:
        "Indexing homo_sapiens CDNA with Salmon"
    threads:
        10
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(8192 + 1024 * attempt, 15360)
        ),
        time_min = (
            lambda wildcards, attempt: min(25 * attempt, 120)
        )
    params:
        extra = "--keepDuplicates --perfectHash"
    log:
        "logs/salmon/index_homo_sapiens.log"
    wrapper:
        f"{wrapper_version}/bio/salmon/index"


def salmon_sample_pair_w(wildcards: Any) -> Dict[str, str]:
    return {
        "r1": design_dict[Upstream_file][wildcards.sample]
        "r2": design_dict[Downstream_file][wildcards.sample]
    }


rule salmon_quant:
    input:
        unpack(salmon_sample_pair_w),
        index = "salmon/index/homo_sapiens",
        gtf = "resources/homo_sapiens.gtf"
    output:
        quant = "salmon/quant/{sample}/quant.sf"
    message:
        "Quantifying {wildcards.sample} with Salmon"
    threads:
        10
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(8192 + 1024 * attempt, 15360)
        ),
        time_min = (
            lambda wildcards, attempt: min(45 * attempt, 120)
        )
    params:
        libtype = "A",
        extra = "--numBootstraps 100 --validateMappings --gcBias --seqBias --geneMap resources/homo_sapiens.gtf"
    log:
        "logs/salmon/quant/homo_sapiens_{sample}.log"
    wrapper:
        f"{wrapper_version}/bio/salmon/quant"


rule tx2gene:
    input:
        gtf = "resources/Homo_sapiens.gtf"
    output:
        tsv = temp("deseq2/Homo_sapiens.tsv")
    message:
        "Building T2G table"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 512, 1024)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 10, 20)
        )
    log:
        "logs/tx2gene.log"
    wrapper:
        f"{git}/tx_to_tgene/bio/tx_to_gene/gtf"

rule pandas_merge:
    input:
        quant = expand(
            "salmon/quant/{sample}/quant.genes.sf",
            sample=design.index.tolist()
        ),
        tx2gene = "deseq2/Homo_sapiens.tsv"
    output:
        tsv = report(
            "salmon/aggregated/TPM.counts.tsv",
            caption="../report/aggregated.TPM.counts.rst",
            category="Counts"
        )
    message:
        "Aggregating salmon counts"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    log:
        "logs/pandas_merge.log"
    wrapper:
        f"{git}/pandas-merge/bio/pandas/salmon"


rule box_count:
    input:
        "salmon/aggregated/TPM.counts.tsv"
    output:
        png = report(
            "figures/box_counts.png",
            caption="../../reports/box.counts.rst",
            category="Figures"
        )
    message:
        "Plotting comparative boxplots of each sample's counts"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 1024, 10240)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    log:
        "logs/box_count.log"
    wrapper:
        f"{git}/pandas-merge/bio/seaborn/box-counts"


rule pairwise_scatterplot:
    input:
        counts = "salmon/aggregated/TPM.counts.tsv"
    output:
        png = report(
            "figures/pairwise_scatterplot.png",
            caption="../../reports/pairwise_scatterplot.rst",
            category="Figures"
        )
    message:
        "Drawing pairwise scatterplot"
    threads:
        1
    resources:
        mem_mb = (
            lambda wildcards, attempt: min(attempt * 8192, 16384)
        ),
        time_min = (
            lambda wildcards, attempt: min(attempt * 20, 200)
        )
    log:
        "logs/pairwise_scatterplot.log"
    wrapper:
        f"{git}/pandas-merge/bio/seaborn/pairwise-scatterplot"
